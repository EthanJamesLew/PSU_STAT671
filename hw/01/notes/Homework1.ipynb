{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Classifier\n",
    "\n",
    "## Problem\n",
    "1. Finish the derivation of the simple classifier provided in class\n",
    "2. Use the [Iris Data Set](https://en.wikipedia.org/wiki/Iris_flower_data_set). Create a classifier for the labels \"I.setosa\" vs \"I.versicolor\" using 80% of the data. Compute the classification error using the remaining 20%. Then, repeat the problem for the labels \"I.virginica\" vs \"I.versicolor\". Report your results in a clear and concise form.\n",
    "\n",
    "## Getting the Data\n",
    "\n",
    "[Scikit-Learn](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) has the data already in its library. For comprehensibility, the data was moved to a pandas data frame to match the wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width  species\n",
      "0             5.1          3.5           1.4          0.2        0\n",
      "1             4.9          3.0           1.4          0.2        0\n",
      "2             4.7          3.2           1.3          0.2        0\n",
      "3             4.6          3.1           1.5          0.2        0\n",
      "4             5.0          3.6           1.4          0.2        0\n",
      "..            ...          ...           ...          ...      ...\n",
      "145           6.7          3.0           5.2          2.3        2\n",
      "146           6.3          2.5           5.0          1.9        2\n",
      "147           6.5          3.0           5.2          2.0        2\n",
      "148           6.2          3.4           5.4          2.3        2\n",
      "149           5.9          3.0           5.1          1.8        2\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "iris_sk=load_iris()\n",
    "species_lp={0:'I.setosa', 1:'I. versicolor', 2:'I. virginica'}\n",
    "iris_df={'sepal_length':iris_sk['data'][:,0], 'sepal_width':iris_sk['data'][:,1], 'petal_length':iris_sk['data'][:,2],\n",
    "        'petal_width':iris_sk['data'][:,3], 'species':iris_sk['target']}\n",
    "iris_df=pd.DataFrame(data=iris_df)\n",
    "print(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Data\n",
    "\n",
    "As mentioned some data needs to be saved for verififcation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal_length  sepal_width  petal_length  petal_width  species\n",
      "0            5.1          3.5           1.4          0.2        0\n",
      "1            4.9          3.0           1.4          0.2        0\n",
      "2            4.7          3.2           1.3          0.2        0\n",
      "3            4.6          3.1           1.5          0.2        0\n",
      "4            5.0          3.6           1.4          0.2        0\n",
      "..           ...          ...           ...          ...      ...\n",
      "95           5.7          3.0           4.2          1.2        1\n",
      "96           5.7          2.9           4.2          1.3        1\n",
      "97           6.2          2.9           4.3          1.3        1\n",
      "98           5.1          2.5           3.0          1.1        1\n",
      "99           5.7          2.8           4.1          1.3        1\n",
      "\n",
      "[80 rows x 5 columns]\n",
      "    sepal_length  sepal_width  petal_length  petal_width  species\n",
      "10           5.4          3.7           1.5          0.2        0\n",
      "13           4.3          3.0           1.1          0.1        0\n",
      "14           5.8          4.0           1.2          0.2        0\n",
      "15           5.7          4.4           1.5          0.4        0\n",
      "20           5.4          3.4           1.7          0.2        0\n",
      "24           4.8          3.4           1.9          0.2        0\n",
      "31           5.4          3.4           1.5          0.4        0\n",
      "35           5.0          3.2           1.2          0.2        0\n",
      "37           4.9          3.6           1.4          0.1        0\n",
      "41           4.5          2.3           1.3          0.3        0\n",
      "45           4.8          3.0           1.4          0.3        0\n",
      "53           5.5          2.3           4.0          1.3        1\n",
      "62           6.0          2.2           4.0          1.0        1\n",
      "74           6.4          2.9           4.3          1.3        1\n",
      "76           6.8          2.8           4.8          1.4        1\n",
      "81           5.5          2.4           3.7          1.0        1\n",
      "86           6.7          3.1           4.7          1.5        1\n",
      "87           6.3          2.3           4.4          1.3        1\n",
      "92           5.8          2.6           4.0          1.2        1\n",
      "94           5.6          2.7           4.2          1.3        1\n"
     ]
    }
   ],
   "source": [
    "def partition_df(df, ratio):\n",
    "    N = df.shape[0]\n",
    "    M = round(N*ratio)\n",
    "    train = np.zeros((N), dtype=np.bool)\n",
    "    train[0:M] = 1\n",
    "    np.random.shuffle(train)\n",
    "    train_df = df[train]\n",
    "    val_df = df[~train]\n",
    "    return train_df, val_df\n",
    "\n",
    "# Get the two species to classify\n",
    "test1_df = iris_df.loc[iris_df['species'] < 2]\n",
    "\n",
    "# Get training and validation sets\n",
    "train1_df, ver1_df = partition_df(test1_df, 0.8)\n",
    "print(train1_df)\n",
    "print(ver1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk: 0.0\n",
      "Empirical Risk: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get the midpoints\n",
    "cm = train1_df.loc[train1_df['species'] == 0].mean(axis = 0) \n",
    "cp = train1_df.loc[train1_df['species'] == 1].mean(axis = 0) \n",
    "cm = np.array(cm)[:-1]\n",
    "cp = np.array(cp)[:-1]\n",
    "c = (cp + cm)/2\n",
    "\n",
    "def classify(x, cp, cm, c):\n",
    "    return np.sign(np.dot(cp - cm, x - c))\n",
    "\n",
    "# Run classifier on validation data\n",
    "true = np.array(ver1_df)[:, -1]*2-1 \n",
    "val = np.array(ver1_df)[:, :-1] \n",
    "test = np.array([classify(x, cp, cm, c) for x in val])\n",
    "     \n",
    "test_error = 1/ver1_df.shape[0]*np.sum(1/2*abs(test-true))\n",
    "print('Risk: %s' % str(test_error))\n",
    "\n",
    "# Run classifier on validation data\n",
    "true_t = np.array(train1_df)[:, -1]*2-1 \n",
    "val_t = np.array(train1_df)[:, :-1] \n",
    "test_t = np.array([classify(x, cp, cm, c) for x in val_t])\n",
    "test_error = 1/train1_df.shape[0]*np.sum(1/2*abs(test_t-true_t))\n",
    "print('Empirical Risk: %s' % str(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "Consider a training set $\\left\\{\\left(x_{1}, y_{1}\\right), \\ldots,\\left(x_{n}, y_{n}\\right)\\right\\}$, with $x_{i} \\in \\mathbb{R}^{d}$ and $y_{i} \\in-1,1$.  The perceptron is one of the oldest algorithm in machine learning.  Historical notes are provided [here](https://en.wikipedia.org/wiki/Perceptron). The  perceptron  is  a  linear  classifier $f(x)=w^{T} x$ where $w \\in \\mathbb{R}^{d}$. The algorithm for computing $w$ is as follows:\n",
    "\n",
    "Init: $w \\leftarrow y_{1} x_{1}$ <br />\n",
    "&emsp;for $i=2 \\ldots n$ do <br />\n",
    "&emsp;&emsp;if $y_{i} w^{T} x_{i}<0$ then $w \\leftarrow w+y_{i} x_{i}$ <br />\n",
    "&emsp;&emsp;end if <br />\n",
    "end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3031.07\n",
      "3257.8600000000006\n",
      "0.0\n",
      "3014.0099999999998\n",
      "3158.3599999999997\n",
      "2744.45\n",
      "2973.4300000000003\n",
      "2992.0800000000004\n",
      "2818.73\n",
      "3200.75\n",
      "2974.3899999999994\n",
      "3283.9399999999996\n",
      "2970.53\n",
      "2914.5799999999995\n",
      "2555.5199999999995\n",
      "2807.899999999999\n",
      "2638.1\n",
      "2686.4199999999996\n",
      "2699.2199999999993\n",
      "2619.5599999999995\n",
      "2422.4599999999996\n",
      "2402.9399999999996\n",
      "2632.97\n",
      "2682.5299999999993\n",
      "2296.65\n",
      "2463.48\n",
      "2018.75\n",
      "2290.46\n",
      "2203.6\n",
      "1947.76\n",
      "2204.59\n",
      "2276.6\n",
      "2164.5799999999995\n",
      "1878.0999999999997\n",
      "2104.4299999999994\n",
      "1919.0099999999995\n",
      "3030.7499999999995\n",
      "2852.0299999999993\n",
      "3036.5099999999993\n",
      "2848.6999999999994\n",
      "2621.49\n",
      "2880.8699999999994\n",
      "2142.9499999999994\n",
      "2873.459999999999\n",
      "2383.41\n",
      "2157.7499999999995\n",
      "2651.0599999999995\n",
      "2773.8299999999995\n",
      "2445.1599999999994\n",
      "2890.7199999999993\n",
      "2631.3499999999995\n",
      "2544.9099999999994\n",
      "2687.2299999999996\n",
      "2441.9099999999994\n",
      "2800.1399999999994\n",
      "2629.6399999999994\n",
      "2819.0699999999993\n",
      "2750.8099999999995\n",
      "2854.4799999999996\n",
      "3005.1799999999994\n",
      "2718.6099999999997\n",
      "2399.8899999999994\n",
      "2387.5399999999995\n",
      "2520.129999999999\n",
      "2810.0499999999993\n",
      "2581.95\n",
      "2782.0499999999993\n",
      "2547.3499999999995\n",
      "2446.8199999999993\n",
      "2525.1399999999994\n",
      "2767.2399999999993\n",
      "2156.1099999999997\n",
      "2584.4399999999996\n",
      "2578.6399999999994\n",
      "2720.2699999999995\n",
      "2155.2399999999993\n",
      "2548.9699999999993\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "w = val_t[2, :]\n",
    "for i in range(3, train1_df.shape[0]):\n",
    "    print(np.dot(w, val_t[i,:]))\n",
    "    if true_t[i]*np.dot(w, val_t[i,:]) <= 0:\n",
    "        w += true_t[i]*val_t[i,:]\n",
    "percept = [np.sign(np.dot(w, x)) for x in val]\n",
    "risk = np.sum(1/2*np.abs(percept-true))\n",
    "print(percept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "Write  the  kernalized  perceptron  algorithm. Provide a pseudo-code.\n",
    "\n",
    "### Solution\n",
    "\n",
    "A kernel makes its decision from the equation\n",
    "\n",
    "\\begin{equation}\n",
    "f_k(x) = \\operatorname{sgn}\\left(\\sum_{i=1}^{m} y_{i} \\alpha_{i} k\\left(x, x_{i}\\right)\\right),\n",
    "\\end{equation}\n",
    "\n",
    "whereas the perceptron's decision function can be expressed as\n",
    "\n",
    "\\begin{equation}\n",
    "f_p(x) = \\operatorname{sgn} \\left( w^T x \\right)\n",
    "\\end{equation}\n",
    "\n",
    "$w$ was generated by successively adding terms $y_i x_i$ upon a misclassification condition. Allow the indices of misclassified points to be described by a set $U$ where its elements $u \\in \\mathbb N$. The decision function, then, can be described by\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "f_p(x) &= \\operatorname{sgn} \\left( \\langle \\sum_{i \\in U} y_i x_i, x \\rangle \\right) \\\\ \n",
    "&= \\operatorname{sgn} \\left( \\sum_{i \\in U} y_i k \\left( x_i, x \\right) \\right) \\\\\n",
    "&= \\operatorname{sgn} \\left( \\sum_{i = 1}^{m} y_i a_i k \\left( x_i, x \\right) \\right) \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "for $a_i$ defined by\n",
    "\n",
    "\\begin{equation}\n",
    "a_i=\\left\\{\\begin{array}{ll}{1} & {\\text { if } i \\in U} \\\\ {0} & {\\text { if } i \\notin U}\\end{array}\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "Write  the  code  for  data  in  2  dimensions,  similarly  than  for  the  simple  classifier. Show 3 examples using 3 different kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernels over $\\mathcal{X} = \\mathbb R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x = (x_1, x_2) \\in \\mathbb R^2$ and $y=\\left(y_{1}, y_{2}\\right) \\in \\mathbb{R}^{2}$, \n",
    "\n",
    "## 1\n",
    "Let\n",
    "\n",
    "\\begin{equation}\n",
    "\\phi(x)=\\left(x_{1}^{2}, \\sqrt{2} x_{1} x_{2}, x_{2}^{2}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Verify that $\\phi(x)^{T} \\phi(y)=\\left(x^{T} y\\right)^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "Evaluate the right side, \n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\left(x^{T} y\\right)^{2} &= \\left( x_1 y_1+ x_2y_2 \\right)^2 \\\\\n",
    "&= x_1^2 y_1^2 + 2 x_1 y_1 y_1 y_2 + x^2_2 y^2_2. \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Evaluate the left side,\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\phi(x)^{T} \\phi(y) &= \\left[\\begin{array}{llll}{x_1^2} & {\\sqrt{2} x_1 x_2} & {x_2^2}\\end{array}\\right] \\left[\\begin{array}{c}{y_1^2} \\\\ {\\sqrt{2} y_1 y_2} \\\\ {y_2^2}\\end{array}\\right] \\\\\n",
    "&= x_1^2 y_1^2 + 2 x_1 y_1 y_1 y_2 + x^2_2 y^2_2. \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "Find a function $\\phi(x): \\mathbb{R}^{2} \\mapsto \\mathbb{R}^{6}$ such that for any $(x, y), \\phi(x)^{T} \\phi(y)=\\left(x^{T} y+1\\right)^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\phi(x)^{T} \\phi(y) &= \\left(x^Ty + 1 \\right)^2 \\\\\n",
    "&= \\left(x^T y \\right)^2 + 2x^T y + 1 \\\\\n",
    "&= x_1^2 y_1^2 + 2 x_1 y_1 y_1 y_2 + x^2_2 y^2_2 + 2x_1 y_1 + 2 x_2 y_2 + 1\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Observing the symmetry,\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\phi(x) = \\left[\\begin{array}{c}{x_1^2} \\\\ {\\sqrt{2} x_1 x_2} \\\\ {x_2^2} \\\\ {\\sqrt{2}x_1} \\\\ {\\sqrt{2} x_2} \\\\ {1}\\end{array}\\right]\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "Find a function $\\phi(x): \\mathbb{R}^{2} \\mapsto \\mathbb{R}^{9}$ such that for any $(x, y), \\phi(x)^{T} \\phi(y)=\\left(x^{T} y+1\\right)^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "An obvious choice is\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\phi(x) = \\left[\\begin{array}{c}{x_1^2} \\\\ {\\sqrt{2} x_1 x_2} \\\\ {x_2^2} \\\\ {\\sqrt{2}x_1} \\\\ {\\sqrt{2} x_2} \\\\ {1} \\\\ {0} \\\\ {0} \\\\ {0}\\end{array}\\right]\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "The inner product is unitary invariant. So, any $\\phi' = U \\phi $ will also satisfy as a solution such that $U^TU=I$ holds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "Verify that\n",
    "\n",
    "\\begin{equation}\n",
    "K(x, y)=\\left(1+x^{T} y\\right)^{d}\n",
    "\\end{equation}\n",
    "\n",
    "for $d=1,2 \\ldots$ is a positive definite kernel.\n",
    "\n",
    "### Solution\n",
    "\n",
    "A kernel, $k(x_i, x_j)$ is positive definite if for a set of numbers $a_1, a_2, ..., a_m \\in \\mathbb R$,\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^{m} \\sum_{j=1}^{m} a_{i} a_{j} K\\left(x_{i}, x_{j}\\right) \\geq 0\n",
    "\\end{equation}\n",
    "\n",
    "By substitution, the left side is\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^{m} \\sum_{j=1}^{m} a_{i} a_{j} \\left(1+x_i^{T} x_j\\right)^{d}.\n",
    "\\end{equation}\n",
    "\n",
    "This permits the binomial expansion,\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^{m} \\sum_{j=1}^{m} a_{i} a_{j} \\sum_{k=0}^{d} \\binom{d}{k} 1^{d-k} \\left(x_i^{T} x_j\\right)^k = \\sum_{k=0}^{d}  \\binom{d}{k} \\sum_{i=1}^{m} \\sum_{j=1}^{m} a_{i} a_{j} \\left(x_i^{T} x_j\\right)^k.\n",
    "\\end{equation}\n",
    "\n",
    "#### Property \n",
    "\n",
    "*Given a family of positive definite kernels $\\left( K_i \\right)_{i \\in \\mathbb N}$, $K_i: \\mathcal X \\times \\mathcal X \\rightarrow \\mathbb R$, the sum $\\sum_{i=1}^{n} \\lambda_{i} K_{i}$ is positive definite given $\\lambda_{1}, \\ldots, \\lambda_{n} \\geq 0$.*\n",
    "\n",
    "Therefore, as $\\binom{d}{k} > 0$, to show that $K(x,y)$ is positive definite, it is suffcient to shows that $K'(x,y) = \\left(x^{T} y\\right)^k$ is positive definite for $k \\in \\mathbb N$.\n",
    "\n",
    "\\begin{equation}\n",
    " \\sum_{j=1}^{m} a_{i} a_{j} \\left(x_i^{T} x_j\\right)^k = \\sum_{j=1}^{m} a_{i} a_{j} \\prod_{l=1}^{k} \\left(x_i^{T} x_j\\right).\n",
    "\\end{equation}\n",
    "\n",
    "#### Property \n",
    "\n",
    "*Given a family of positive definite kernels $\\left( K_i \\right)_{i \\in \\mathbb N}$, $K_i: \\mathcal X \\times \\mathcal X \\rightarrow \\mathbb R$, $K\\left(\\left(x_{1}, \\ldots, x_{n}\\right),\\left(y_{1}, \\ldots, y_{n}\\right)\\right)=\\prod_{i=1}^{n} K_{i}\\left(x_{i}, y_{i}\\right)$ is a positive definite kernel.*\n",
    "\n",
    "Therefore, $K'(x,y) = \\left(x^{T} y\\right)^k$ is positive definite, implying that $K(x, y)=\\left(1+x^{T} y\\right)^{d}$ is also positive definite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\n",
    "Can you find a function $\\phi: \\mathbb{R}^{2} \\mapsto H$, where $H$ is an inner product space such that for any $(x, y),<\\phi(x), \\phi(y)>_{H}=x^{T} y-1$?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
